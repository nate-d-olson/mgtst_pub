---
title: "Relative Abundance Error Rate"
author: "Nate Olson"
date: '`r Sys.Date()`'
output:
  bookdown::pdf_document2: 
    toc: FALSE
---

```{r relAbuSetup, include=FALSE}
## TODO feature count table
library(nlme)
library(ape)
library(multcomp)
library(kableExtra)
library(tidyverse)
library(forcats)
library(stringr)
library(ggpubr)
library(ggridges)
nb_counts <- readRDS("~/Desktop/nb_counts_titrations.RDS")
pa_summary_anno_df <- readRDS("~/Desktop/pa_summary_anno_df.RDS")
theta_est <- readRDS("~/Desktop/bootstrap_theta_estimates.rds")
```

```{r relAbuMunge, echo = FALSE, message = FALSE, warning = FALSE}
### TODO - move to separate Rmd and generate data_frame
pre_post_prop <- nb_counts %>% 
    ungroup() %>% 
    filter(t_fctr %in% c(0,20)) %>% 
    mutate(end_point = if_else(t_fctr == 0 , "post", "pre")) %>% 
    dplyr::select(-t_fctr) %>% 
    ## setting values to 0 when one or more of the PCR replicates are 0 for titration end-points
    spread(end_point,nb_prop, fill = 0)

prop_inferred <- theta_est %>% 
    filter(pipe == "unclustered") %>% 
    ungroup() %>%
    mutate(t_fctr = factor(t_fctr, levels = c(0:5, 10, 15, 20))) %>% 
    dplyr::select(biosample_id, theta_hat_mean, t_fctr) %>% 
    right_join(nb_counts) %>% right_join(pre_post_prop) %>% 
    filter(t_fctr %in% c(1:5,10,15)) %>% 
    ## Using inferred theta estimates to calculate expected values
    mutate(inferred_prop = post * theta_hat_mean + pre * (1 - theta_hat_mean))

## Excluding mix and unmix specific features
## Only including features observed in all or none of the four pre- post- PCR replicates
## Features with relative abundance estimates and expected values less than 1e-5, these are features that we would not expect to consistently observe in a PCR replicate for the given sequencing depth, ~100k 
## Excluding titrations where the inferred theta values are less than 1
pa_filter <- pa_summary_anno_df %>% 
    filter(pa_specific == "unspecific") %>% 
    dplyr::select(biosample_id, pipe, feature_id, full_pre, T00, T20, pa_mixed) %>% 
    filter(T00 %in% c(0,4), T20 %in% c(0,4))

prop_inferred <- prop_inferred %>% 
    right_join(pa_filter) %>% 
    # filter(nb_prop > 1e-5, 
    #        inferred_prop > 1e-5,
    #        theta_hat_mean > 0)
    ## Filtering absed on 1/median library size
    filter(nb_prop > 1/73571,
           inferred_prop > 1/73571,
           theta_hat_mean > 0)


#### Error Rate Calculations
rel_abu_error <- prop_inferred %>% 
    mutate(t_fctr = factor(t_fctr, levels = c(1:5, 10, 15))) %>% 
    mutate(inferred_error = abs(nb_prop - inferred_prop),
           inferred_error_rate = inferred_error/inferred_prop) 

rel_abu_error_summary <-  rel_abu_error %>% 
    group_by(pipe, biosample_id, feature_id) %>% 
    summarise(median_rel_abu = median(nb_prop),
              median_error = median(inferred_error_rate),
              iqr_error = IQR(inferred_error_rate),
              rcov_error = iqr_error/median_error, 
              mean_error = mean(inferred_error_rate),
              var_error = var(inferred_error_rate),
              cov_error = var_error/mean_error) 

### Error rate boxplot and outlier annotation
error_boxplot <- rel_abu_error %>% group_by(pipe, biosample_id, feature_id) %>% 
    summarise(median_error = median(inferred_error_rate)) %>%
    ggplot() + 
    geom_boxplot(aes(x = pipe, y = median_error, color = pipe), outlier.shape = NA) + 
    facet_wrap(~biosample_id, ncol = 1) + 
    theme_bw() + theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "Individual", y = "Median", color = "Pipeline")

## Annotating features as outliers based on boxplot
error_plot_dat <- ggplot_build(error_boxplot)$data[[1]] %>% 
    mutate(pipe = fct_recode(factor(group), 
                             dada2 = "1", 
                             mothur = "2", 
                             qiime = "3",
                             unclustered = "4"),
           biosample_id = fct_recode(PANEL, 
                                     E01JH0004 = "1", 
                                     E01JH0011 = "2", 
                                     E01JH0016 = "3", 
                                     E01JH0017 = "4", 
                                     E01JH0038 = "5"))
outlier_error_dat <- error_plot_dat %>% 
    dplyr::select(ymin, ymax, pipe, biosample_id)

rel_error_outlier_cat <- rel_abu_error_summary %>% 
    left_join(outlier_error_dat) %>% 
    mutate(outlier_cat = if_else(median_error < ymin | median_error > ymax, 
                                 "outlier","inlier")) 

## Robust COV Analysis
rcov_boxplot <- rel_abu_error_summary %>%
    ggplot() + 
    geom_boxplot(aes(x = pipe, y = rcov_error, color = pipe), outlier.shape = NA) + 
    facet_wrap(~biosample_id, ncol = 1) + 
    theme_bw() + theme(axis.text.x = element_text(angle = 90)) +
    labs(x = "Individual", y = "RCOV", color = "Pipeline") 


## Annotating features as outliers based on boxplot
rcov_plot_dat <- ggplot_build(rcov_boxplot)$data[[1]] %>% 
    mutate(pipe = fct_recode(factor(group), 
                             dada2 = "1", 
                             mothur = "2", 
                             qiime = "3",
                             unclustered = "4"),
           biosample_id = fct_recode(PANEL, 
                                     E01JH0004 = "1", 
                                     E01JH0011 = "2", 
                                     E01JH0016 = "3", 
                                     E01JH0017 = "4", 
                                     E01JH0038 = "5"))
outlier_rcov_dat <- rcov_plot_dat %>% 
    dplyr::select(ymin, ymax, pipe, biosample_id)

rcov_outlier_cat <- rel_abu_error_summary %>% 
    left_join(outlier_rcov_dat) %>% 
    mutate(outlier_cat = if_else(rcov_error < ymin | rcov_error > ymax, 
                                 "outlier","inlier"))

## Feature-level error summary data frame
rel_error_summary <- rel_error_outlier_cat %>% 
    dplyr::rename(error_cat = outlier_cat) %>% 
    dplyr::select(-ymin, -ymax) %>% 
    left_join(rcov_outlier_cat) %>% 
    dplyr::rename(rcov_cat = outlier_cat)

### Plot Code -----------------------------------------------------------------
## Observed v. Expected Regression plot
relAbuOvE <- prop_inferred %>%
    ggplot() +
    geom_abline(aes(intercept = 0, slope = 1), color = "grey60", linetype = 2) +
    geom_smooth(aes(x = inferred_prop, y = nb_prop, color = pipe), method = "lm") +
    facet_wrap(~biosample_id, ncol = 1) +
    scale_y_log10() + scale_x_log10() +
    theme_bw() +
    labs(x = "Expected",
         y = "Observed", 
         color = "Pipeline")

relAbuErrorDist <- rel_abu_error %>% 
    ggplot() + 
    geom_density_ridges(aes(x = inferred_error_rate, y = pipe, color = pipe), alpha = 0.5) + 
    facet_wrap(~biosample_id, ncol = 1) + theme_bw() + 
    labs(x = "Error Rate", y = "Pipeline", color = "Pipeline") +
    scale_x_log10()

# ggsave(relAbuOvE, "~/Desktop/quant_exp_vs_obs.png", dpi = 450)

## Median Error Pipeline Comparison
ymin <- ggplot_build(error_boxplot)$data[[1]]$ymin %>% min()
ymax <- ggplot_build(error_boxplot)$data[[1]]$ymax %>% max()
error_boxplot <- error_boxplot + coord_cartesian(ylim = c(ymin, ymax))

# ggsave(error_boxplot, "~/Desktop/quant_bias.png", dpi = 450) 

## RCOV Error Pipeline Comparison
ymin <- ggplot_build(rcov_boxplot)$data[[1]]$ymin %>% min()
ymax <- ggplot_build(rcov_boxplot)$data[[1]]$ymax %>% max()
rcov_boxplot <- rcov_boxplot + coord_cartesian(ylim = c(ymin, ymax))

# ggsave(rcov_boxplot, "~/Desktop/quant_variance.png", dpi = 450) 
```


```{r relAbuStats, echo = FALSE, message = FALSE, warning = FALSE}
## Bias - Error rate
error_fit_dat <- rel_error_outlier_cat %>% 
    ungroup() %>% 
    filter(outlier_cat == "inlier", pipe != "unclustered") %>% 
    mutate(pipe = factor(pipe))

# Fitting mixed effects model with individual as the fixed effect
error_fit <- nlme::lme(median_error ~ pipe, random =  ~ 1 | biosample_id, 
                       data = error_fit_dat)  

# Pipe error estimates
dada_error <- error_fit$coefficients$fixed['(Intercept)']
mothur_error <- dada_error + error_fit$coefficients$fixed['pipemothur']
qiime_error <- dada_error + error_fit$coefficients$fixed['pipeqiime']

# Post-hoc test to check for pipeline differences 
## based on fit pipeline estimates are all negative, using alternative greater to determine which pipelines are closer to zero
error_post_hoc <- glht(error_fit, linfct = mcp(pipe = "Tukey"), alternative = "less") 

error_tukey_p <- summary(error_post_hoc)$test$pvalues 
error_tukey_t <- summary(error_post_hoc)$test$tstat

# Checking whether indiviudal or pipeline contributes more to the overal vaiance
error_var <- ape::varcomp(error_fit)

## Variance - RCOV
rcov_fit_dat <- rcov_outlier_cat %>% 
    ungroup() %>% 
    filter(outlier_cat == "inlier", pipe != "unclustered") %>% 
    mutate(pipe = factor(pipe))

# Fitting mixed effects model with individual as the fixed effect
rcov_fit <- nlme::lme(rcov_error ~ pipe, random =  ~ 1 | biosample_id, 
                      data = rcov_fit_dat)

# Pipe RCOV estimates
dada_rcov <- rcov_fit$coefficients$fixed['(Intercept)']
mothur_rcov <- dada_rcov + rcov_fit$coefficients$fixed['pipemothur']
qiime_rcov <- dada_rcov + rcov_fit$coefficients$fixed['pipeqiime']

# Checking whether indiviudal or pipeline contributes more to the overal vaiance
rcov_var <- ape::varcomp(rcov_fit)  
```

```{r relAbuFeatTbl, echo = FALSE, warning = FALSE, message = FALSE}
# rel_abu_error_summary %>% 
#       group_by(pipe, biosample_id) %>% 
#       summarise(count = n()) %>% 
#       spread(biosample_id, count) %>% 
#       knitr::kable(booktabs = TRUE, caption = "Number of features by pipeline and individual used in the relative abundance error rate analysis.")
```



```{r relAbuError, fig.cap = "(A) Expected and observed count relationship. Orange line indicates expected 1-to-1 relationship. Blue line a smoothed regression line of the observed and expected value relationship. Features with observed and expected relative abundance values less than 1/median library size were excluded from the figure. Distribution of feature-level relative abundance (B) median error rates and (C) robust coefficient of variation (RCOV) by individual and pipeline.", echo = FALSE, warning=FALSE, message = FALSE, fig.height = 8}
ggarrange(relAbuOvE,
          relAbuErrorDist + rremove("y.text"),
          error_boxplot + rremove("x.text"), 
          rcov_boxplot  + rremove("x.text"), 
          labels = "AUTO",
          align = "h", ncol = 4, nrow = 1,
          common.legend = TRUE,
          legend = "bottom")
```

```{r relAbuErrorTbl, echo = FALSE, warning = FALSE, message = FALSE}
rel_abu_error_summary %>% 
      group_by(pipe, biosample_id) %>% 
      summarise(med_med_error = median(median_error), 
                min_med_error = min(median_error), 
                max_med_error = max(median_error),
                med_rcov_error = median(rcov_error), 
                min_rcov_error = min(rcov_error), 
                max_rcov_error = max(rcov_error)) %>% 
      ## Value ranges
      # mutate(Median = paste0(round(med_med_error,2), " (",
      #                        round(max_med_error,2), "-",
      #                        round(min_med_error,2),")"),
      #        RCOV = paste0(round(med_rcov_error,2), " (",
      #                      round(max_rcov_error,2), "-",
      #                      round(min_rcov_error,2),")")) %>% 
      # Max values only 
      mutate(Median = max_med_error, RCOV = max_rcov_error) %>% 
     dplyr::select(pipe, biosample_id, Median, RCOV) %>%
      dplyr::rename(Pipeline = pipe, Individual = biosample_id) %>%
      gather("Metric","value", -Pipeline, -Individual) %>% 
      spread(Individual, value) %>% 
      arrange(Metric) %>% 
     dplyr::select(Metric, Pipeline, E01JH0004, E01JH0011, E01JH0016, E01JH0017, E01JH0038) %>% 
      knitr::kable(booktabs = TRUE, caption = "Maximum feature-level error rate bias (median error rate) and variance (robust COV) by pipeline and individual.", digits = 2) %>% 
      collapse_rows(columns = 1)
```

Overall aggreement between the inferred and observed relative abundance was high for all individuals and bioinformatic pipelines (Fig. \@ref(fig:relAbuError)A). 
The pre- and post-exposure estimated relative abundance and inferred $\theta$ values were used to calculate titration and feature level error rates. 
To prevent over-fitting, $\theta$ estimates for the unclustered pipeline were used to calculate the error rates for the other three pipelines.  
Only features observed in all pre- and post-exposure PCR replicates and pre- and post-exposure specific features were included in the analysis (Table \@ref(tab:relAbuFeatTbl)). 
Pre- and post-exposure specific features were defined as present in all four PCR replicates of the pre-exposure or post-exposure PCR replicates, respectively, but none of the PCR replicates for the other unmixed sample.
There is lower confidence in the relative abundance of a feature in the pre- or post-exposure unmixed samples when the feature is observed in some of the 4 PCR replicates, therefore these features were not included in the error analysis.
The deviation from the expected value on the low end varies by biological replicate and pipeline. 

Next we evaluated the feature-level quantitative accuracy of the relative abundance values by comparing the distribution of the median error and robust coefficient of variation ($RCOV=(IQR)/|median|$)for the relative abundance error rate (Fig. \@ref(fig:relAbuError)). 
Feature-level median error rates and RCOV were compared across pipelines and individuals using a mixed effects model. 
Large error rates and RCOV values were observed for all pipelines (Table  \@ref(tab:relAbuErrorTbl)). 
Features with large error rates, defined as $1.5\times IQR$ from the median, were excluded from the analysis to prevent outliers from biasing the comparison. 
The mean feature-level error rate by pipeline was negative for all three pipelines (DADA2 `r round(dada_error,2)`, Mothur `r round(mothur_error,2)`, and QIIME `r round(qiime_error,2)`). 
Multiple comparisons test (Tukey) was used to test for significant differences in feature-level error between pipelines. 
A one-sided alternative hypothesis to determine which pipelines had a smaller, closer to zero, feature-level error rate. 
The Mothur and DADA2 mean feature-level error rates were closer to zero and signficantly different from the QIIME pipeline, (Mothur v. QIIME t = `r  round(error_tukey_t['qiime - mothur'],2)`, p = `r round(error_tukey_p[error_tukey_t == error_tukey_t['qiime - mothur']],2)`; DADA2 v. QIIME t = `r  round(error_tukey_t['qiime - dada2'],2)`, p = `r round(error_tukey_p[error_tukey_t == error_tukey_t['qiime - dada2']],2)`). 
Though the Mothur and DADA2 mean feature-level error rates were not significantly different from eachother, (t = `r  round(error_tukey_t['mothur - dada2'],2)`, p = `r round(error_tukey_p[error_tukey_t == error_tukey_t['mothur - dada2']],2)`).
Unlike feature-level error rates, large RCOV was observed for all individuals and pipelines (Table \@ref(tab:relAbuErrorTbl)). 
Outlier values were also excluded from the RCOV analysis. 
The feature-level RCOV was not significantly different between pipelines, Mothur = `r round(mothur_rcov,2)`, QIIME = `r round(qiime_rcov,2) ` and DADA2 = `r round(dada_rcov)` (Fig. \@ref(fig:relAbuError)C). 

In an attempt to identify feature characteristics that could be attributed to poor performance the feature-level error-rate and RCOV were compared to the unmixed sample relative abundance and relative abundance across the titrations. 
Additionally, feature-level relative abundance error metrics were compared across individuals to try and identify any relationship between poor performance and phylogeny. 
Outlier feature-level error-rates had lower median relative abundance, but not RCOV (Fig. \@ref(fig:errorOut)). 
The median relative abundance was significantly lower for features identified as outliers based on the feature-level error rate, but only when considering features with positive error rates. 
This is likely due to the more extreme error rates all being positive. 
For the RCOV the feature-level median relative abundance values were not significantly different between the outlier and non-outlier features.  
The error rate is dependent on the accuracy of the relative abundance estimates for the unmixed pre- and post-exposure samples. 
The feature-level median error-rate and RCOV was compared to the the unmixed sample variance/mean relative abundance to determine if extreme error-rate and RCOV values could be attributed to variability in relative abundance between PCR replicates for the unmixed samples. 
The variance/mean for the unmixed samples was lower for the outliers compared to the non-outliers for both the feature-level error rate and RCOV. 
Investigation of relationship between phylogeny and feature-level relative abundance error metrics (Fig. \@ref(fig:relAbuTreeFig)). 
Only features included in the relative abundance error analysis for at least three of the five individuals were included in the figure. 
No clear relationship between feature-level error rate or RCOV and phylogeny of representative sequences. 


