---
title: "Count Table Value Assessment"
author: "Nate Olson"
date: "March 22, 2017"
output:
  pdf_document: default
  html_document: default
---

```{r setup, warning=FALSE, message=FALSE, echo = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(ProjectTemplate)
cwd <- getwd()
setwd("../")
load.project()
setwd(cwd)
```

Using observed count values for the unmixed pre- and post-treatment samples we are able to estimate count values for the titrations. 
We can then evaluate how well the observed count values agree with the expected values for biological replicates, pipelines, and for individual features. 
We are only including informative features in this analysis, features with non-zero count values for all four unmixed pre- and/or post-treatment PCR replicates. 

```{r echo = FALSE}
pipeline_dir <- "../../mgtst_pipelines"
mrexp <- get_mrexp(pipeline_dir) 

## Extracting a tidy dataframe with count values from MRexperiment objects
get_count_df <- function(mrobj){
      mrobj <- cumNorm(mrobj, p = 0.75)
      mrobj %>%
            # not sure whether or not to normalize counts prior to analysis
            MRcounts(norm = TRUE, log = FALSE, sl = 1000) %>%  
            as.data.frame() %>% 
            rownames_to_column(var = "feature_id") %>% 
            gather("id","count", -feature_id)
}

count_df <- mrexp %>% map_df(get_count_df, .id = "pipe") 

## Getting information about number of replicates with observed counts for feature characterization, e.g. pre-full and post-full or both full
count_replicate_df <- pData(mrexp$dada2) %>% right_join(count_df) %>% 
      filter(biosample_id != "NTC") %>%
      mutate(detect = if_else(count > 0, 1, 0)) %>%
      group_by(pipe, biosample_id, titration, t_fctr, feature_id) %>% 
      summarise(total_detect = sum(detect),
                n_replicates = n(),
                med_count = median(count),
                avg_count = mean(count)) %>%
      mutate(detect_prop = total_detect/n_replicates) %>% 
      select(-total_detect) 

## Pre and post full features are not necessarily pre or post specific
post_full <- count_replicate_df %>%
      ungroup() %>% 
      filter(detect_prop == 1, t_fctr == 0) %>% 
      select(pipe, biosample_id, feature_id, med_count) %>% 
      dplyr::rename(post_count = med_count)
pre_full <- count_replicate_df %>%
      ungroup() %>% 
      filter(detect_prop == 1, t_fctr == 20) %>% 
      select(pipe, biosample_id, feature_id, med_count) %>% 
      dplyr::rename(pre_count = med_count) 

pre_post_full <- pre_full %>% 
      full_join(post_full) %>% 
      mutate(pre_count = if_else(is.na(pre_count), 0, pre_count),
             post_count = if_else(is.na(post_count), 0, post_count)) 

titration_list <- data_frame(titration = c(1:5,10,15)) %>% 
      mutate(post_prop = 2^-titration) %>% list() %>% rep(nrow(pre_post_full))

titration_pred <- pre_post_full %>% ungroup() %>% 
      add_column(titration = titration_list) %>% unnest() %>% 
      mutate(exp_count = post_count * post_prop + pre_count * (1-post_prop))  

quant_df <- count_replicate_df %>% 
      ungroup() %>% 
      filter(titration %in% c(1:5,10,15)) %>%  
      dplyr::rename(med_obs_count = med_count, avg_obs_count = avg_count) %>% 
      right_join(titration_pred) %>% 
      mutate(residual = exp_count - med_obs_count)# %>% 
      ## Removing features with no observed counts
      # filter(med_obs_count != 0) %>% 
      ## Removing features not observed in all four replicate PCRs
      # filter(detect_prop == 1) 
```

## Overall Relationship Between Expected and Observed Count Values

We will first explore how well the observed count values agree with our expectations for the different pipelines and biological replicates \@ref(fig:bioPipeObsVsExp). 
Consistent deviation from expectation for a pipeline is an indicator of a potential error in the clustering method where biologically unrealated sequences are grouped together. 
Although consistency between the expected and observed count values only indicates that unrelated sequences are not grouped together at a detectable rate. 
Consistent deviation from expectation for biological replicates indicates a potential error in our assumptions regarding how the titrations were generated, namely the relative proportion of unmixed pre- and post-treatment samples in a titration. 


```{r bioPipeObsVsExp, fig.cap = "Relationship between the expected and observed count values. The median pre- and post- treatment count values were used to calculate the expected values and the median observed values were used as the observed value. The dark grey line indicates the expected 1 to 1 relationship between the observed and expected count values."}
quant_df %>%
      ggplot() + 
      geom_point(aes(x = med_obs_count, y = exp_count), fill = "darkblue", 
                 color = "white", alpha = 0.5, shape = 21) + 
      geom_abline(aes(intercept = 0, slope =1), color = "darkorange") +
     facet_wrap(~pipe, scales = "free")+ theme_bw() + 
      labs(y = "Expected Count", x = "Observed Count")
```

We can further explore the relationship between expected and observed count values by comparing the residuals (expected count - observed count) to the expected count values \@ref(fig:bioPipeResidual). 
Fitting a linear regression to the residuals and expected counts we can identify pipelines and biological replicates where the observed count values are not consistent with the expected count values. 
The assumption is that there is a one to one relationship between the expected and observed count values, therefore the estimated slope and intercepts of the residuals versus expected counts are 0. 



```{r bioPipeResidual, fig.cap = "Relationship between the expected counts and residuals (expected - observed). The median count values for the four replicate PCRs were used to for the observed count value and calculating the expected count value. Each point represent the relationship between the residual and expected count values for a titration and feature. The orange line is a linear regression, residual ~ expected count, independently fit to each biological replicate and pipeline combination."}
quant_df %>%
      ggplot() +
      geom_point(aes(x = exp_count, y = residual), fill = "darkblue", 
                 color = "white", alpha = 0.5, shape = 21) +
      geom_smooth(aes(x = exp_count, y = residual), 
            method = "lm", se = TRUE, color = "darkorange") +
      facet_grid(biosample_id~pipe, scales = "free_x", space = "free") + theme_bw() +
      labs(x = "Expected Count", y = "Residuals")

```

```{r}
quant_df %>%
      ggplot() +
      geom_point(aes(x = exp_count, y = residual), fill = "darkblue", 
                 color = "white", alpha = 0.5, shape = 21) +
      geom_smooth(aes(x = exp_count, y = residual), 
            method = "lm", se = TRUE, color = "darkorange") +
      facet_grid(titration~pipe, scales = "free_x", space = "free") + theme_bw() +
      labs(x = "Expected Count", y = "Residuals")
```


We fit a linear model where the slope was estimated independently for each pipeline and biological replicate combinations. 

$$C_{residual} = C_{exp}\beta_1 + \beta_0$$

$$C_{exp} = C_{post} (t^{ -2}) + C_{pre} (1- t^{ -2})$$

and,

$$C_{residual} = C_{exp} - C_{obs_t}$$ 

For the model $C_{obs}$ is the median obseved counts for titration $t$, $C_{post}$ and $C_{pre}$ are the median observed counts for the unmixed pre- and post-treatment samples, and $t$ is the titration factor. 
The slope estimates for biological replicate E01JH0038 are consistently furthest from the expected values \@ref(fig:bioPipeEstimates). 
For the different pipelines, DADA2 estimates were consistently closer to the expected values and Mothur was the furthest. __NOTE__ These results have changed when using log2 transformation or performing CSS normalization.

```{r}
quant_fit <- quant_df %>% 
      group_by(pipe, biosample_id) %>% 
      nest() %>% 
      mutate(fit = map(data, ~lm(residual~exp_count, data = .)))

quant_tidy <- quant_fit %>% 
      select(pipe, biosample_id, fit) %>% 
      mutate(tidy = map(fit, broom::tidy)) %>% 
      select(-fit) %>% 
      unnest() %>% 
      mutate(term = if_else(term == "exp_count", "Slope","Intercept"))
est_df <- quant_tidy %>% select(pipe, biosample_id, term, estimate) %>% 
      spread(term, estimate)
error_df <- quant_tidy %>% select(pipe, biosample_id, term, std.error) %>% 
      mutate(term = paste0(term,"Error")) %>% 
      spread(term, std.error)
scatter_df <- left_join(est_df, error_df)
```

```{r bioPipeEstimates, fig.cap = "Slope and intercept estimates for linear models fit to residuals ~ expected counts, estimate standard errors are indicated by the error bars. The expectation is that both the slope and intercept are 0. Shape and color indicate pipeline and biological replicate, respectively."}
scatter_df %>% 
      ggplot(aes(x = Slope, y = Intercept, color = biosample_id)) +
      geom_hline(aes(yintercept = 0)) + geom_vline(aes(xintercept = 0)) +
      geom_errorbar(aes(ymin = Intercept - InterceptError, ymax = Intercept + InterceptError)) + 
      geom_errorbarh(aes(xmin = Slope - SlopeError, xmax = Slope + SlopeError)) + 
      geom_point(aes(shape = pipe), size = 4) +
      theme_bw() +
      labs(shape = "Pipeline", color = "Biological\nReplicate")
```


## Fitting Regression Models to Individual Features 
We also wanted to develop a better understanding of how well the count values for individual features agree with the expected count values. 
We fit the same model to individual features as we did for each combination of biological replicates and pipelines.

```{r}
quant_nested <- quant_df %>% 
      group_by(pipe, biosample_id, feature_id) %>% 
      nest() 

quant_fit <- quant_nested %>% 
      mutate(fit = map(data,~lm(residual ~ exp_count, data = .)))

quant_fit_tidy <- quant_fit %>% 
      mutate(fit_summary = map(fit, broom::tidy)) %>% 
      select(-data, -fit) %>% unnest() %>% 
      mutate(term = if_else(term == "(Intercept)", "Intercept","Slope")) 

quant_fit_glance <- quant_fit %>% 
      mutate(fit_summary = map(fit, broom::glance)) %>% 
      select(-data, -fit) %>% unnest() %>% 
      select(-statistic, -p.value) 
```  


#### Exploring Model Slope and Intercept Estimates
The intercept estimates are centered around 0, the expected value, whereas the slope estimates have a bimodal distribution with peaks around 0 and 1 \@ref(fig:featureEstimates). 
Slope of 1 indicates that the residuals increase with the expected value. 
Large slope and intercept estimates (excluded from the plot) were observed and indicate significant changes in the observed count values relative to the expected count values. 
These outliers are not internally consistent and warrant investigation into potential causes for the inconsistency. 

```{r}
quant_fit_tidy %>% 
      filter((term == "Intercept" & estimate < 0.025 & estimate > -0.025) |
             (term == "Slope" & estimate < 5 & estimate > -5)) %>% 
      ggplot() + geom_density(aes(x = estimate, color = pipe)) +
      facet_wrap(~term, ncol = 1, scales = "free") +
      theme_bw() +
      labs(x = "Slope Estimate", y = "Density", color = "Pipelines")
```

```{r}
quant_fit_tidy %>% group_by(pipe, biosample_id, term) %>% 
      summarise(est_median = median(estimate) %>% round(3), 
                est_max = max(estimate) %>% round(2),
                est_min = min(estimate) %>% round(2)) %>% 
      mutate(est_summary = paste0(est_median, " (", est_min," -- ",est_max,")")) %>% 
      select(pipe, biosample_id, term, est_summary) %>% spread(term, est_summary) %>% 
      knitr::kable(align = c("l","l","r","r"))
```

We wanted to explore the individual features to first distinguish between features that are consistent and inconsistent with our expectations and then identify any potential characteristics may account for features not performing according to expectation.  
We will rank the features based on the euclidean distance of the slope and intercept estimates from the expected value (0,0). 

```{r}
quant_r2 <- quant_fit_glance %>% 
      select(pipe, biosample_id, feature_id, adj.r.squared) 

quant_coef <- quant_fit_tidy %>% 
      select(pipe, biosample_id, feature_id, term, estimate) #%>% 
      # spread(term, estimate)

quant_lm_values <- quant_coef %>% left_join(quant_r2)

quant_dist <- quant_lm_values %>% spread(term, estimate) %>% 
      mutate(opti_dist = sqrt(Slope^2 + Intercept^2))

consistent_features <- quant_dist %>% top_n(4, desc(opti_dist)) %>% 
      mutate(category = "consistent")
inconsistent_features <- quant_dist %>% top_n(4, opti_dist) %>%
      mutate(category = "inconsistent") 
example_features <- bind_rows(consistent_features, inconsistent_features)

example_features_quant <- quant_fit %>% select(-fit) %>%
      right_join(example_features) %>%  unnest() 
```

```{r featureRank, fig.cap = "Linear model for the features and slope and intercept estimates that are the most consistent and inconsistent with our expectation based on the distances of the slope and intercept estimates from the origin."}
example_features_quant %>% ggplot(aes(x = exp_count, y = residual)) + 
      geom_point(aes(color = factor(titration))) + 
      geom_smooth(method = "lm", se = TRUE, color = "grey60") + 
      facet_wrap(category~feature_id, scales = "free", nrow = 2) +
      theme_bw() + theme(axis.text.x = element_text(angle = 90))
```

We want to group features into sets that are consistent and inconsistent with our expectations. 
One observation is that the range of expected values appears to be smaller for features with slope and intercept estimates that are inconsistent with out expectation (Appendix - Range - Dist correlation). 
While expected count value range is correlated with distance of the slope and intercept estimates from 0, their is no clear separation of features into distinct groups. 
We additionally wanted to see if the $R^2$ model estimates were correlated with the distance 




```{r}
example_features %>% knitr::kable(digits = 3)
```


```{r}
ggplot(quant_dist) + geom_histogram(aes(x = opti_dist)) + scale_x_log10()
```


```{r}
ggplot(quant_dist) + geom_boxplot(aes(x = pipe, y = opti_dist)) + scale_y_log10()
```

When aggregating features to the genus level there is no longer a pipeline effect.

The distances from the optimal estimation are statistically different between platforms
```{r}
kruskal.test(quant_dist$opti_dist, factor(quant_dist$biosample_id)) %>% broom::tidy()
kruskal.test(quant_dist$opti_dist, factor(quant_dist$pipe)) %>% broom::tidy()
```


## Session information
```{r}
s_info <- devtools::session_info()
print(s_info$platform)
s_info$packages %>% filter(`*` == "*") %>% select(-`*`) %>% 
      knitr::kable()
``` 

## Appendix
### Euclidian Distance and Expected Value Range Relationship
The distance in the slope and intercept estimates from the origin (0,0) for features with wider expected values ranges is consistently smaller than features with narrower expected value ranges. 
Though features with narrow expected value ranges have slope and intercept estimates that are both near and far from the origin. 
Therefore a small range in expected values does fully explain the inconsistency in the feature count values with our expectations. 
```{r}
quant_range <- quant_df %>% group_by(pipe,biosample_id, feature_id) %>% 
      summarise(min_exp = min(exp_count), max_exp = max(exp_count)) %>% 
      mutate(range_exp = max_exp - min_exp) %>% 
      select(-min_exp, -max_exp) %>% left_join(quant_dist)
```

```{r}
cor.test(quant_range$range_exp, quant_range$opti_dist,method = "spearman")
```

```{r}
quant_range %>% 
      ggplot() + geom_point(aes(x = opti_dist, y = range_exp))
```

### Exploring Relationship between Model Estimates and R^2
The $R^2$ value is correlated with the slope and intercept estimates distance from the expected values there is no clear separation of features into subset that can be used to categorize features and consistent or inconsistent with expectations base on the model $R^2$. 

94.4% of features have slope and intercept values between -5 and 5. 

```{r}
quant_lm_values %>%  spread(term, estimate) %>% 
      filter(Slope < 5, Slope > -5, Intercept <5, Intercept > -5) %>% 
      ggplot() + geom_point(aes(x = Slope, y = Intercept, color = adj.r.squared)) + theme_bw()
```

```{r}
total_features <- quant_lm_values %>%  spread(term, estimate) %>% nrow()
subset_features <- quant_lm_values %>%  spread(term, estimate) %>% 
      filter(Slope < 5, Slope > -5, Intercept <5, Intercept > -5)  %>% nrow()
subset_features/total_features
subset_features
```


```{r}
quant_dist %>% ggplot() + geom_point(aes(x = opti_dist, y = adj.r.squared), alpha = 0.25) + 
      geom_smooth(aes(x = opti_dist, y = adj.r.squared, color = biosample_id)) + 
      scale_x_log10() + facet_wrap(~biosample_id) + theme_bw()
```

```{r}
quant_dist %>% ggplot() + geom_point(aes(x = opti_dist, y = adj.r.squared), alpha = 0.25) + 
      geom_smooth(aes(x = opti_dist, y = adj.r.squared, color = pipe)) + 
      scale_x_log10() + 
      facet_grid(biosample_id~pipe) + theme_bw()
```