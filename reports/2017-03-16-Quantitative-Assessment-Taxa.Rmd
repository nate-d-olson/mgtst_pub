---
title: "Quantitative Assessment"
author: "Nate Olson"
date: '`r Sys.Date()`'
always_allow_html: yes
output:
  pdf_document: default
  html_document: default
---

```{r setup, warning=FALSE, message=FALSE, echo = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(ProjectTemplate)
cwd <- getwd()
setwd("../")
load.project()
setwd(cwd)
library(ggfortify)
```


## Overview
Quantitative analysis of informative features, features with observed count values for all pre- and/or post-treatment PCR replicates. 
Calculated the expected count values and explored three different regression models for performing feature level analysis. 

## Preparing Data For Analysis

```{r echo = FALSE}
pipeline_dir <- "../../mgtst_pipelines"
mrexp <- get_mrexp(pipeline_dir)
```

```{r}
## Extracting a tidy dataframe with count values from MRexpiment objects
get_count_df <- function(mrobj){
      mrobj <- aggregateByTaxonomy(mrobj, lvl = "Rank6", norm = FALSE,
                                   log = FALSE, sl = 1)
      mrobj <- cumNorm(mrobj, p = 0.75)
      mrobj %>%
            # not sure whether or not to normalize counts prior to analysis
            MRcounts(norm = TRUE, log = FALSE, sl = 1) %>%  
            #MRcounts(sl = 1) %>% 
            as.data.frame() %>% 
            rownames_to_column(var = "feature_id") %>% 
            gather("id","count", -feature_id)
}

count_df <- mrexp %>% map_df(get_count_df, .id = "pipe")
```


```{r}
## Getting information about number of replicates with observed counts for feature characterization, e.g. pre-full and post-full or both full
count_replicate_df <- pData(mrexp$dada2) %>% right_join(count_df) %>% 
      filter(biosample_id != "NTC") %>%
      mutate(detect = if_else(count > 0, 1, 0)) %>%
      group_by(pipe, biosample_id, titration, t_fctr, feature_id) %>% 
      summarise(total_detect = sum(detect),
                n_replicates = n(),
                med_count = median(count),
                avg_count = mean(count)) %>%
      mutate(detect_prop = total_detect/n_replicates) %>% 
      select(-total_detect)
```

Extracting informative features, features with observed counts in all four unmixed pre- and/or post-treatment replicates. 

```{r}
## Pre and post full features are not necessarily pre or post specific
post_full <- count_replicate_df %>%
      ungroup() %>% 
      filter(detect_prop == 1, t_fctr == 0) %>% 
      select(pipe, biosample_id, feature_id, med_count) %>% 
      dplyr::rename(post_count = med_count)
pre_full <- count_replicate_df %>%
      ungroup() %>% 
      filter(detect_prop == 1, t_fctr == 20) %>% 
      select(pipe, biosample_id, feature_id, med_count) %>% 
      dplyr::rename(pre_count = med_count)
```


```{r}
pre_post_full <- pre_full %>% 
      full_join(post_full) %>% 
      mutate(pre_count = if_else(is.na(pre_count), 0, pre_count),
             post_count = if_else(is.na(post_count), 0, post_count))
```

```{r}
titration_list <- data_frame(titration = c(1:5,10,15)) %>% 
      mutate(post_prop = 2^-titration) %>% list() %>% rep(nrow(pre_post_full))

titration_pred <- pre_post_full %>% ungroup() %>% 
      add_column(titration = titration_list) %>% unnest() %>% 
      mutate(exp_count = post_count * post_prop + pre_count * (1-post_prop))
```

```{r}
quant_df <- count_replicate_df %>% 
      ungroup() %>% 
      filter(titration %in% c(1:5,10,15)) %>%  
      dplyr::rename(med_obs_count = med_count, avg_obs_count = avg_count) %>% 
      right_join(titration_pred) %>% 
      mutate(residual = exp_count - med_obs_count)
```

## Relationship Between Expected and Observed Count Values

* For the figure the median pre and post treatment count values were used to calculate the expected values and the median observed values were used as the observed value. 
* The dark grey line indicates the expected 1 to 1 relationship between the observed and expected count values.  
* In general the higher the obsered count the better the agreement between the observed and expected counts. (Potential artifact of the log-log scale plot.)    
* Number of features with no observed counts, points on y-axis, with a range of expected count values. 
* The expected count values were consistently lower than the observed count values for all pipelines and biological replicates. Especially for biological replicate the E01JH0016 and the QIIME pipeline.

```{r}
quant_df %>%
      ggplot() + 
      geom_point(aes(x = med_obs_count, y = exp_count, color = factor(titration)), alpha = 0.25) + 
      geom_abline(aes(intercept = 0, slope =1), color = "grey40") +
      facet_grid(biosample_id~pipe)+ theme_bw() + scale_y_log10() + scale_x_log10() +
      labs(y = "Expected Count", x = "Observed Count")
```

Same plot as above but not split by biological replicate and non-transformed axis.
```{r}
quant_df %>%
      ggplot() + 
      geom_point(aes(x = med_obs_count, y = exp_count, color = factor(titration)), alpha = 0.25) + 
      geom_abline(aes(intercept = 0, slope =1), color = "grey40") +
     facet_wrap(~pipe, scales = "free")+ theme_bw() + 
      labs(y = "Expected Count", x = "Observed Count")
```

* Residual distribution is consistent across biological replicates.  
* There is greater distribution in the mothur residuals compared to the other pipelines.  
* The distribution variance increases with titration and with titration 10 and 15 being bimodal. 

```{r}
quant_df %>% 
      ggplot() + geom_histogram(aes(x = residual, fill = biosample_id)) +
      facet_grid(titration~pipe) + theme_bw() + scale_y_log10()
```




## Fitting Regression Models to Individual Features 
Using linear regression to evaluate how well the relationship between the observed and predicted counts agrees with the expected one to one relationship. 

Excluding titrations 10 and 15 from following analysis. 

```{r}
quant_nested <- quant_df %>% 
      # Can samples with higher titration factors to see if values improve
      filter(titration < 10) %>%
      group_by(pipe, biosample_id, feature_id) %>% 
      nest() 
```

### Model Comparison

1. $C_{obs} =  C_{exp}\beta_1 + \beta_0$, including the intercept in the model. Expectation $\beta_1 = 1$ and $\beta_0=0$.
2. $C_{obs} =  [C_{post} (t^{ -2}) + C_{pre} (1- t^{ -2})] \beta_1 + 0$, setting the intercept to 0. Expectation $\beta_1 = 1$.  
3. $C_{residual} = [C_{post} (t^{ -2}) + C_{pre} (1- t^{ -2})] \beta_1$, residuals as deviance from expectation.  

Model , where $C_{obs}$ is the median obseved counts for titration $t$, $C_{post}$ and $C_{pre}$ are the median observed counts for the unmixed pre- and post-treatment samples, and $t$ is the titration factor. 
$C_{exp} = [C_{post} (t^{ -2}) + C_{pre} (1- t^{ -2})]$ and $C_{residual}= C_{obs} - C_{exp}$.

Arbitrarily looking at the first feature
```{r}
dat <- quant_nested$data[[1]]
```

Relationship between the observed and expected count values. 
The line represents the fitted regression line (including intercept in the model) and grey area the standard error. 
The black line represents the assumed 1 to 1 relationship between the observed and expected count values.

```{r}
ggplot(dat) + 
      geom_point(aes(x = exp_count, y = med_obs_count, color = factor(titration))) + 
      geom_smooth(aes(x = exp_count, y = med_obs_count), 
                  method = "lm", se = TRUE, color = "grey60") + 
      geom_abline(aes(slope = 1, intercept = 0)) + 
      theme_bw() +
      labs(x = "Expected Count", y = "Observed Count", color = "Titration\nFactor")
```

#### Including intercept in the model
$C_{obs} =  C_{exp}\beta_1 + \beta_0$  

```{r}
fit_wint <- lm(med_obs_count~exp_count, quant_nested$data[[1]])
summary(fit_wint)
```

```{r}
autoplot(fit_wint)
```

#### Setting intercept to 0 

$C_{obs} =  C_{exp}\beta_1$   
 
```{r}
fit_int0 <- lm(med_obs_count~exp_count + 0, quant_nested$data[[1]])
summary(fit_int0)
```

```{r}
autoplot(fit_int0)
```

#### Fitting the residuals ~ expected counts

```{r}
fit_resid <- lm(residual ~ exp_count, data = dat)
summary(fit_resid )
``` 

```{r}
autoplot(fit_resid)
```


### Model fit summary 
More of the variance in the data is explained when forcing the intercept to 0. 
Though fitting the model to the residuals is a more interpretable result. 
Will use the model fitting the residuals versus expected counts for interpretability. 

```{r}
list(intercept = fit_wint, zero_intercept = fit_int0, residuals = fit_resid) %>% 
      map_df(broom::glance, .id = "Model") %>% knitr::kable(digits = 3)
```




## Evaluating Full Dataset 

Fitting all features to the model described above. 
```{r}
quant_fit <- quant_nested %>% 
      mutate(fit = map(data,~lm(residual ~ exp_count, data = .)))
```

```{r}
quant_fit_tidy <- quant_fit %>% 
      mutate(fit_summary = map(fit, broom::tidy)) %>% 
      select(-data, -fit) %>% unnest() %>% 
      mutate(term = if_else(term == "(Intercept)", "Intercept","Slope"))
```

Warning message for unreliable summary, due to "essentially perfect fit"

```{r}
quant_fit_glance <- quant_fit %>% 
      mutate(fit_summary = map(fit, broom::glance)) %>% 
      select(-data, -fit) %>% unnest() %>% 
      select(-statistic, -p.value) 
```


#### Exploring Model Slope and Intercept Estimates

##### Slope Estimates
```{r}
quant_fit_tidy %>% filter(term == "Slope") %>% .$estimate %>% summary()
```

Slope estimate distributions. 
(Excluding outlier slope estimates.)  
Bimodal distribution with peaks at 1 and 0. 
Peak around 0 represents the desired 1 to 1 relationship between the expected and observed values. 
Slope of 1 indicates that the residuals increase with the expected value. 
This maybe an artifact of the heteroscedastic nature of count data, if so, log2 transforming the count data may address this. 
Large slope estimates (excluded from the plot) indicate significant changes in the observed count values relative to the expected count values. 
These outliers are not internally consistent and warrant investigation into potential causes for the inconsistency. 


```{r}
quant_fit_tidy %>% 
      filter(term == "Slope") %>%
      ggplot() + geom_density(aes(x = estimate, color = pipe)) + 
      theme_bw() +
      labs(x = "Slope Estimate", y = "Density") +
      xlim(-5,5)
```

##### Intercept Estimates

```{r}
quant_fit_tidy %>% filter(term == "Intercept") %>% .$estimate %>% summary()
```

Intercept estimate distributions. 
(Excluding outlier intercept estimates.)  
The intercept values are centered around 0 as expected, though estimates much greater and less than 0 were observed. 


```{r}
quant_fit_tidy %>% 
      filter(term == "Intercept") %>%
      ggplot() + geom_density(aes(x = estimate, color = pipe)) + 
      theme_bw() +
      labs(x = "Intercept Estimate", y = "Density") + 
      xlim(-0.05,0.05)
```


#### Variance explained by the model 
The models accounted for the most of the variance in the data. 

```{r}
quant_fit_glance %>% ggplot() + 
      geom_histogram(aes(x = adj.r.squared, fill = pipe)) + 
      facet_wrap(~pipe, ncol = 1) + 
      theme_bw() + theme(legend.position = "none")
```

### Exploring Relationship between Model Estimates and R^2

```{r}
quant_r2 <- quant_fit_glance %>% 
      select(pipe, biosample_id, feature_id, adj.r.squared) 

quant_coef <- quant_fit_tidy %>% 
      select(pipe, biosample_id, feature_id, term, estimate) #%>% 
      # spread(term, estimate)

quant_lm_values <- quant_coef %>% left_join(quant_r2)
```

Higher $R^2$ values correlate with intercept estimates of 0 but slope estimates of 0 have lower $R^2$ values. 
The lower $R^2$ values for slope estimates of 0 ... I think this makes sense as the remaining variability is due to random noise that than not be accounted for in the linear model.

```{r}
quant_lm_values %>% filter(estimate < 100, estimate > -100) %>% 
ggplot() + 
      geom_density_2d(aes(x = estimate, y = adj.r.squared)) + 
      facet_grid(term~.) +
      theme_bw()
```  


```{r}
quant_lm_values %>% filter(estimate < 3, estimate > -3) %>% 
ggplot() + 
      geom_point(aes(x = estimate, y = adj.r.squared), alpha = 0.1) + 
      facet_grid(term~.) + 
      theme_bw()
```  


Features that are performing according to expectation
```{r}
good_features <- quant_lm_values %>%  spread(term, estimate) %>% 
      filter(Intercept <0.0025, Intercept > -0.0025, Slope > -0.005, Slope < 0.005) 
good_feature_quant <- quant_fit %>% select(-fit) %>%
      right_join(good_features) %>%  unnest() 
```
```{r}
good_features %>% knitr::kable(digits = 3)
```

```{r}
good_feature_quant %>% ggplot() + 
      geom_point(aes(x = exp_count, y =residual, color = factor(titration))) + 
      geom_smooth(aes(x = exp_count,y =residual), 
                  method = lm, se = TRUE, color = "grey80") +
      facet_wrap(~feature_id, scales = "free") + 
      theme_bw() +
      labs(x = "Expected Count", y = "Residuals", color = "Titration") 
```


```{r}
bad_features <- quant_lm_values %>% 
      spread(term, estimate) %>% 
      filter(Intercept > 10 | Intercept < - 10, Slope < -3 | Slope > 3) 
bad_feature_quant <- quant_fit %>% select(-fit) %>%
      right_join(bad_features) %>%  unnest() 
```

The $R^2$ values are closer to 1 for features with slope and intercept values that are significantly different from the expected values. 
```{r}
bad_features %>% knitr::kable()
```


For these features the range of observed values is much larger than the expected value range.
```{r}
bad_feature_quant %>% ggplot() + 
      geom_point(aes(x = exp_count, 
                     y = residual, 
                     color = factor(titration))) + 
      geom_smooth(aes(x = exp_count,y =residual), 
                  method = lm, se = TRUE, color = "grey80") +
      facet_wrap(~feature_id, scales = "free") + 
      theme_bw() +
      labs(x = "Expected Count", y = "Residuals", color = "Titration")
```


### Summary  
* Overall the pipelines are internally consistent with the expected count values correlating with the observed count values.   
* Performed feature level analysis by fitting a regression model of the expected count values to the observed count values.  
* Can use the feature level slope, intercept, and $R^2$ values to identify features that are consistent and inconsistent with expectation.

## Session information
```{r}
s_info <- devtools::session_info()
print(s_info$platform)
s_info$packages %>% filter(`*` == "*") %>% select(-`*`) %>% 
      knitr::kable()
``` 