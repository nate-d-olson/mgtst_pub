---
title: "Discussion"
author: "Nate Olson"
date: '`r Sys.Date()`'
output:
  bookdown::pdf_document2:
    toc: FALSE
bibliography: [mgtst.bib]
---


We assessed the quantitative and qualitative characteristics of count tables generated using different bioinformatic pipelines and 16S rRNA marker-gene survey mixture dataset.
The mixture dataset followed a two-sample titration mixture design, where DNA collected before and after exposure to pathogenic _Escherichia coli_ from five vaccine trial participants (subjects) were mixed following a $log_2$ dilution series (Fig. \@ref(fig:countExperimentalDesign)).
Qualitative count table characteristics were assessed using relative abundance information for features observed only in titrations and unmixed samples.
We quantitatively assed count tables by comparing feature relative and differential abundance to expected values.


### Count Table Assessment Demonstration
We demonstrated our novel assessment approach by evaluating count tables generated using different bioinformatic pipelines, QIIME, Mothur, and DADA2.
The Mothur pipeline uses _de novo_ clustering for feature inference [@westcott2017opticlust; @schloss2009introducing].
Pairwise distances used in clustering are calculated using a multiple sequence alignment.
The quality filtered paired-end reads are merged into contigs.
The pipeline the aligns contigs to a reference multiple sequence alignment and removes uninformative positions in the multiple sequence alignment.
The QIIME pipeline uses open-reference clustering where merged paired-end reads are first assigned to reference cluster centers [@Rideout2014; @Caporaso2010].
Next QIIME clusters unassigned reads _de novo_.
Unlike Mothur, the QIIME clustering method uses pairwise sequence distances calculated from pairwise sequence alignments.
As a result, the QIIME pairwise distances are calculated using the full ~436 bp sequences whereas Mothur pairwise distances were calculated using a 270 bp multiple sequence alignment.
The DADA2 pipeline uses a probability model and maximization expectation algorithm for feature inference [@callahan2016dada2].
Unlike distance-based clustering methods employed by the Mothur and QIIME pipelines, DADA2 parameters determine if low abundance sequences are grouped with a higher abundance sequence.
As a control, we compared our quantitative assessment results for the three pipelines to a count table of unclustered features.
The unclustered features were generated using the Mothur pipeline preprocessing methods.
<!-- The quantitative and qualitative assessment results provide new insight into the marker-gene-survey measurement process. -->


#### Quantitative Assesssment
<!--
Outline
- Quantitative results
  - Relative abundance
    - Error rates
    - Bias metric
    - Variance metric
  - Differential abundance
    - error rates
    - bias metric
    - variance metric -->
<!--
Notes
- GC issue with other sequencing mehtods but not 16S???
-->

While the relative abundance bias metric was significantly different between pipelines overall, pipeline choice had minimal impact on the quantitative assessment results when accounting for subject-specific effects.
Outlier features, those with extreme quantitative analysis bias and variance metrics, were observed for all pipelines and both relative and differential abundance assessments.
Outlier features could not be attributed to bioinformatic pipelines and are likely due to biases in the molecular biology part of the measurement process.
Outlier features are not likely a pipeline artifact as they were observed in count tables generated using the unclustered pipeline as well as standard bioinformatic pipelines.
We were unable to attribute outlier features to relative abundance values, log fold-change between unmixed samples, and sequence GC content.
Features with extreme metric values were not limited to any specific taxonomic group or phylogenetic clade.
PCR amplification is a well-known bias molecular biology component of the measurement process.
Mismatches in the primer binding regions impact PCR efficiency and are a potential cause for poor feature-specific performance [@wright2014exploiting].
Additional research is needed before outlier features are attributed to mismatches in the primer binding regions.


#### Qualitative Assessment
The qualitative assessment evaluated whether features only observed in unmixed samples or titrations could be explained by sampling alone.
Features present only in the titrations or unmixed samples not due to random sampling are bioinformatic pipeline artifacts.
These artifacts can be categorized as false negative or false positive features.
A false negative occurs when a lower abundance sequence representing an organism within the sample is clustered with a higher abundance sequence from a different organism.
False positives are sequencing or PCR artifacts not appropriately filtered or assigned to an appropriate feature by the bioinformatic pipeline.

<!-- Summary of qualitative assessment results -->

Count table sparsity, the proportion of zero-valued cells, provides additional insight into the qualitative assessment results.
A high rate of false negative features is a potential explanation for the  DADA2 count table's poor performance in the qualitative assessment and comparable sparsity to the other pipelines despite having significantly fewer features (Fig. \@ref(fig:qualPlot), \@ref(tab:pipeQA)).
The DADA2 feature inference algorithm may be aggressively grouping lower abundance true sequences with higher abundance sequences.
As a result, the low abundance sequences are not present in samples leading to increased sparsity and higher abundance unmixed- and titration-specific features.
Adjusting the DADA2 parameters, specifically the `OMEGA_A` parameter in `setDadaOpt`.
Along these lines, the DADA2 documentation states that the default setting for `OMEGA_A` is conservative to prevent false positives at the cost of increasing false negatives [@callahan2016dada2].

False positive features provide an explanation for Mothur and QIIME pipelines having lower proportion of unmixed- and titration-specific features not explained by sampling but high sparsity (Fig. \@ref(fig:qualPlot), \@ref(tab:pipeQA)).
The statistical tests used to determine if the specific features could be explained by sampling only considers feature abundance.
Therefore, the statistical test is not able to distinguish between true low abundance unmixed- and titration-specific features and low abundance sequence artifacts.
Mothur and QIIME count tables have ten times and three times more features compared to DADA2, respectively (Table \@ref(tab:pipeQA)).
While microbial abundance distributions are known to have long tails, it is likely that the observed sparsity is an artifact of the 16S rRNA sequencing measurement process.
Similarly, significantly more features than expected are commonly observed for mock community benchmarking studies evaluating the QIIME and Mothur pipelines [@kozich2013development].


False positive features can be reduced, but not eliminated, using smaller amplicon and prevalence filtering.
The 16S rRNA region sequenced in the study is larger than the region the _de-novo_, and open clustering pipelines were initially developed for, potentially explaining the higher than expected sparsity [@kozich2013development].
The larger region has a smaller overlap between the forward and reverse reads. As a result merging of the forward and reverse reads did not allow for the sequence error correction that occurs when a smaller amplicon is used. <!-- But it's illumina, I'm surprised if this is a true issue.  What level of sequencing correction is presumed/found typically? -->
However, even when targeting smaller regions of the 16S rRNA gene both the _de-novo_ (Mothur) and open-reference clustering (QIIME) pipelines produced count tables with significantly more features than expected in evaluation studies using mock communities.
Prevalence filtering is used to exclude low abundance features, likely predominantly measurement artifacts [@callahan2016].
For example, a study exploring the microbial ecology of the Red-necked stint _Calidris ruficollis_, a migratory shorebird, used a hard filter to validate their study conclusions are not biases by false positive features.
The study authors compared results with and without prevalence filter ensuring that the study conclusions were not biased by using the arbitrary filter or including the low abundant features [@risely2017gut].

<!-- ### Implications for 16S rRNA marker-gene-surveys -->
<!-- __COMMENTED OUT__ -->
<!-- - Implications for false positives and false negatives
  - Primary implication is regarding more likely to impact presence/absence ecological diversity analysis specifically alpha and beta diversity.
  - Alpha diversity
    - Though the number of features in a sample may not accurately reflect the true sample richness.
    - It is unknown if true differences in richness can be detected using the different pipelines.
    - Reference breakaway
  -Beta diversity
    - Impact of false negative and positive feature rates on beta diversity analysis.

<!-- Potentially move to after qual assessment -->
<!-- - 16S rRNA marker-gene-survey methods are better suited for community level analysis. -->
<!-- is this an argument for true metagenomic seq instead of 16S? see recent bracken paper by Salzberg et al-->
  <!-- - Feature-level analysis results, such as differential abundance,
  are susceptible to unknown biases responsible for the observed outlier features.
  - Whereas community level analysis, such as beta diversity, are more robust to the unknown feature-level biases observed in this study.
  - Additional work is needed to further characterize these outliers to increase confidence in the results of feature-level analyses.
  - potential issues with qualitative community analysis based on qualitative assessment.
  - feature-level analysis results should be validated using orthogonal methods when appropriate -->


### Using Mixtures to Assess 16S rRNA Sequencing
Mixtures of environmental samples have previously been used to assess RNAseq and microarray gene expression measurements.
However, this is the first time mixtures have been used to assess microbiome measurement methods.
Our mixture dataset allowed us to develop novel methods for assessing marker-gene-survey computational methods.
Our quantitative assessment allowed for the characterization of relative abundance values using a dataset with a larger number of features and dynamic range compared to assessments using mock communities.
As a result, we were able to identify previously unknown feature specific biases.
Based on our study results additional experiments can be performed to identify the cause of these biases and develop appropriate methods to account for them.
Based on our subject-specific results observation, we recommend that studies based on stool samples seeking inferences in a longitudinal series of multiple subjects carefully estimate bacterial DNA proportions and adjust inferences accordingly.
Additionally, our qualitative assessment results, when combined with sparsity information provide a new method for evaluating how well bioinformatic pipelines account for sequencing artifacts without loss of true biological sequences.


There were also limitations using our mixture dataset.
These limitations included:
Lack of agreement between the proportion of unmixed samples titrations and the mixture design.
The number of features used in the different analysis.
These limitations are described below along with recommendations for addressing them in future studies.


Differences in the proportion of prokaryotic DNA in the samples used to generate the two-sample titrations series results in differences between the true mixture proportions and mixture design.
We attempted to account for differences in mixture proportion from mixture design by estimating mixture proportions using sequence data.
Similar to how the proportion of mRNA in RNA samples used in a previous mixture study.
We were able to use an assay targeting the 16S rRNA gene to detect changes in the concentration of bacterial DNA across titration, but unable to quantify the proportion of bacterial DNA in the unmixed samples using qPCR data.
Using the 16S sequencing data we inferred the proportion of bacterial DNA from the POST sample in each titration.
However, the uncertainty and accuracy of the inference method are not known resulting in an unaccounted for error source.


A better method for quantifying sample bacterial DNA proportion or using samples with consistent proportions would increase the expected value and in-turn error metric accuracy.
Limitations in the prokaryotic DNA qPCR concentration assay precision limit the suitability for use in mixture studies.
Digital PCR provides a more precise alternative to qPCR and is, therefore, a more appropriate method.
Alternatively using samples where the majority of the DNA is prokaryotic would minimize this issue.
Mixtures of environmental samples can also be used to assess shotgun metagenomic methods as well.
As shotgun metagenomics is not a targeted approach, differences in the proportion of bacterial DNA in a sample would not impact the assessment results in the same way as 16S rRNA marker-gene-surveys.


Using samples from a vaccine trial allowed for the use of a specific marker with an expected response, _E. coli_, during methods development.
However, the high level of similarity between the unmixed samples resulted in a limited number of features that could be used in the quantitative assessment results.
Using more diverse samples to generate mixtures would address this issue.


## Conclusions
This two-sample-titration dataset can be used to evaluate and characterize bioinformatic pipelines and clustering methods.
The sequence dataset presented in this study can be processed with any 16S bioinformatic pipeline.
Our quantitative and qualitative assessment can then be performed on the count table and the results compared to those obtained using the pipelines included in this study.
The threee pipelines we evaluated produced sets of features varying in total feature abundance, number of features per samples, and total features.
The objective of any pipeline is to differentiate true biological sequences from artifacts of the measurement process.
In general based on our evalutation results we recommend using for DADA2 for feature-level abundance analysis, e.g. differential abundance testing.
While DADA2 performed poorly in our qualitative assessment, the pipeline had performed better in the quantiative assessment compared to the other pipelines. 
Additionally, the DADA2 poor qualitative assessment results due to false-negative features are unlikely to negatively impact feature-level abundance analysis, though additional research is needed to validate this claim.
When determining which pipeline to use for a study, users should consider whether minimizing false positives (DADA2) or false negatives (Mothur) is more appropriate for their study objectives.
When a sequencing dataset is processed using DADA2, the user can be more confident that an observed feature represents a member of the microbial community and not a measurement artifact.
Pipeline parameter optimization could address DADA2 false-negative issue.
For the Mothur and QIIME pipelines, prevalence filtering will reduce the number of false-positive features.
Feature-level results for any 16S rRNA marker-gene survey should be interpreted with care, as the biases responsible for poor quantitative assessment are unknown.
Addressing both of these issues requires advances in both the molecular biology and computational components of the measurement process.


<!-- There were two primary limitations of the study that were a product of the experimental design.
Only features that were differentially abundant between the PRE and POST were used in the assessment.
Using samples from the vaccine trial provided a specific features, _E. coli_ that could be used during method development.
However, only a limited number of features were differentially abundant between the PRE and POST samples resulting in a smaller set of features that could be used in our assessment.
Generating mixtures of samples with less similarity would increase the number of features used in the assessment.
Additionally, using samples from other environments would increase the taxonomic diversity of features used in the assessment and potentially allowing for a more rigorus evaluation of the relationship between the assessment metrics and phylogeny.
The second limitation of the experimental design was the difference in the proportion of bacterial DNA between the PRE and POST samples.
We were able to use an assay targeting the 16S rRNA gene to detect changes in the concentation of bacterial DNA across titration but we were unable to estimate the proportion of bacterial DNA in the unmixed samples using the qPCR data.
Using the 16S sequencing data we inferred the proportion of bacterial DNA from the POST sample in each titration.
However, the uncertainty and accuracy of the inferrence method is not known resulting in an unaccounted for error source.
A better method for estimating the proportion of bacterial DNA in the unmixed samples would increase the accuracy of the error metrics.
Alternatively samples that are primarily prokaryotic DNA could be used -->
